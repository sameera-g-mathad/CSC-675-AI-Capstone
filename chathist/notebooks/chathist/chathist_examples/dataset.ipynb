{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe55c6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:40,428 - WARNING - train is not present in the config file, falling back to defaults!!!\n"
     ]
    }
   ],
   "source": [
    "from chathist import Tokenizer, InstructionDataLoader,InstructionDataset, InstructionStyle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac88812",
   "metadata": {},
   "source": [
    "### Trying the same of chat dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f24bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_df = pd.read_json(\"hf://datasets/ogrnz/chat-titles/dataset.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c61ca5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['message', 'title'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6828bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Develop a method for clustering astronomical d...</td>\n",
       "      <td>Astronomical Data Clustering Method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of dopamine in the brain as a...</td>\n",
       "      <td>Dopamine as a Neurotransmitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Replace the \\\"XXX\\\" in the following sentence ...</td>\n",
       "      <td>Company Sustainability Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identify the sentence type (declarative, inter...</td>\n",
       "      <td>Sentence Type Identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suggest a book title for a fantasy novel about...</td>\n",
       "      <td>Outlaws in Enchanted Realms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Develop a method for clustering astronomical d...   \n",
       "1  What is the role of dopamine in the brain as a...   \n",
       "2  Replace the \\\"XXX\\\" in the following sentence ...   \n",
       "3  Identify the sentence type (declarative, inter...   \n",
       "4  Suggest a book title for a fantasy novel about...   \n",
       "\n",
       "                                 title  \n",
       "0  Astronomical Data Clustering Method  \n",
       "1       Dopamine as a Neurotransmitter  \n",
       "2     Company Sustainability Objective  \n",
       "3         Sentence Type Identification  \n",
       "4          Outlaws in Enchanted Realms  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c175e396",
   "metadata": {},
   "source": [
    "### Setting tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5310bddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:40,832 - INFO - Setting tokenizer using tiktoken with encoding: gpt2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28719cae",
   "metadata": {},
   "source": [
    "### Creating a dataset using phi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6453eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:41,018 - INFO - phi3 style chosen!!\n"
     ]
    }
   ],
   "source": [
    "style = InstructionStyle.load(style='phi3', input_query=\"<|user|>\\n\", response_query=\"\\n<|llm|>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23ffb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = style.convert_train(chat_df, input_col='message', response_col= 'title', output_col='instruct', new_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c42fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|user|&gt;\\nDevelop a method for clustering astr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|user|&gt;\\nWhat is the role of dopamine in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|user|&gt;\\nReplace the \\\"XXX\\\" in the following...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|user|&gt;\\nIdentify the sentence type (declarat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|user|&gt;\\nSuggest a book title for a fantasy n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instruct\n",
       "0  <|user|>\\nDevelop a method for clustering astr...\n",
       "1  <|user|>\\nWhat is the role of dopamine in the ...\n",
       "2  <|user|>\\nReplace the \\\"XXX\\\" in the following...\n",
       "3  <|user|>\\nIdentify the sentence type (declarat...\n",
       "4  <|user|>\\nSuggest a book title for a fantasy n..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb3a802",
   "metadata": {},
   "source": [
    "### Using InstructionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acd103ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:41,060 - INFO - Setting tokenizer using tiktoken with encoding: gpt2\n"
     ]
    }
   ],
   "source": [
    "dataset = InstructionDataset(df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba197c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = InstructionDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3996d6",
   "metadata": {},
   "source": [
    "### Using InstructionLoader without masking inputs (Phi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader.load(dataset=dataset, batch_size=8, shuffle=True, drop_last=True, mask_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b051271",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61aa753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "468cd20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = first_batch[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d9ac42",
   "metadata": {},
   "source": [
    "-100 is neglected by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aab1c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Summarize the following text for a reader who is in a hurry: Among the many economic challenges brought on by the COVID-19 pandemic, one result has been an increase in the demand for online platforms and services that communities need to conduct their business and stay safe. As more people are working and learning remotely, many businesses are now offering services that they did not previously provide.\n",
      "<|llm|>\n",
      "Economic impact of COVID-19<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ac7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = first_batch[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e09c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|user|>\n",
      "Summarize the following text for a reader who is in a hurry: Among the many economic challenges brought on by the COVID-19 pandemic, one result has been an increase in the demand for online platforms and services that communities need to conduct their business and stay safe. As more people are working and learning remotely, many businesses are now offering services that they did not previously provide.\n",
      "<|llm|>\n",
      "Economic impact of COVID-19<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "230c7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader.load(dataset=dataset, batch_size=8, shuffle=True, drop_last=True, mask_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c9cfd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b954bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a64c161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = first_batch[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c9dcc",
   "metadata": {},
   "source": [
    "-100 is neglected by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32f45989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Summarize the thesis statement of the given article: The article is titled \"The Power of Storytelling in Personal Branding\".\n",
      "<|llm|>\n",
      "Thesis Statement Summary<|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80d5e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = first_batch[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902154cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|user|>\n",
      "Summarize the thesis statement of the given article: The article is titled \"The Power of Storytelling in Personal Branding\".\n",
      "<|llm|>\n",
      "Thesis Statement Summary<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f2b3f",
   "metadata": {},
   "source": [
    "### Using InstructionLoader with masking inputs (Phi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ea26e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader.load(dataset=dataset, batch_size=8, shuffle=True, drop_last=True, mask_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35381233",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec04f640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:41,406 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,407 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,407 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,408 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,409 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,409 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,410 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,411 - INFO - Masking inputs upto response query!!!\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f45e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = first_batch[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8e948",
   "metadata": {},
   "source": [
    "-100 is neglected by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2445c14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Convert the following sentence from present continuous tense to present simple tense: The government is planning several reforms.\n",
      "<|llm|>\n",
      "Tense Conversion Exercise<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88ec7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = first_batch[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08786540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tense Conversion Exercise<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "319c77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader.load(dataset=dataset, batch_size=8, shuffle=True, drop_last=True, mask_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca4d4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f22dd260",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfbc6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = first_batch[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6af9f9e",
   "metadata": {},
   "source": [
    "-100 is neglected by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5edd4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Given an animal, explain what special feature it has: Hummingbird\n",
      "<|llm|>\n",
      "Hummingbird's Unique Feature<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f8e26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = first_batch[1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0936849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|user|>\n",
      "Given an animal, explain what special feature it has: Hummingbird\n",
      "<|llm|>\n",
      "Hummingbird's Unique Feature<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5720739",
   "metadata": {},
   "source": [
    "### Creating a dataset using alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74d957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"###You are a very smart llm and given the input query your job is to predict the title of the input.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "856811aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:41,499 - INFO - alpaca style chosen!!\n"
     ]
    }
   ],
   "source": [
    "style = InstructionStyle.load(style='alpaca', prompt= prompt, input_query=\"### Input:\\n\", response_query=\"\\n### Response:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59be1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = style.convert_train(chat_df, input_col='message', response_col= 'title', output_col='instruct', new_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92a8d5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>###You are a very smart llm and given the inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>###You are a very smart llm and given the inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>###You are a very smart llm and given the inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>###You are a very smart llm and given the inpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>###You are a very smart llm and given the inpu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            instruct\n",
       "0  ###You are a very smart llm and given the inpu...\n",
       "1  ###You are a very smart llm and given the inpu...\n",
       "2  ###You are a very smart llm and given the inpu...\n",
       "3  ###You are a very smart llm and given the inpu...\n",
       "4  ###You are a very smart llm and given the inpu..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c446c7",
   "metadata": {},
   "source": [
    "### Using InstructionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4f82a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InstructionDataset(df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a9a1ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = InstructionDataLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c238f",
   "metadata": {},
   "source": [
    "### Using InstructionLoader without masking inputs (alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "029422f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader.load(dataset=dataset, batch_size=8, shuffle=True, drop_last=True, mask_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36d75418",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a94ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "08734545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = first_batch[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbd4a1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###You are a very smart llm and given the input query your job is to predict the title of the input.\n",
      "### Input:\n",
      "Summarize the core message of this passage: The internet has transformed many aspects of our lives, from our morning routine to the way we do business. We are now able to access information and services faster than ever before and the world has become interconnected at an unprecedented rate.\n",
      "### Response:\n",
      "Impact of Internet Evolution\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "73d88edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = first_batch[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42857336",
   "metadata": {},
   "source": [
    "### Response without masking inputs alpaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5e5f3",
   "metadata": {},
   "source": [
    "-100 is neglected by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8434fd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a very smart llm and given the input query your job is to predict the title of the input.\n",
      "### Input:\n",
      "Summarize the core message of this passage: The internet has transformed many aspects of our lives, from our morning routine to the way we do business. We are now able to access information and services faster than ever before and the world has become interconnected at an unprecedented rate.\n",
      "### Response:\n",
      "Impact of Internet Evolution<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b8843",
   "metadata": {},
   "source": [
    "### Using InstructionLoader without masking inputs (alpaca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58a61c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = loader.load(dataset=dataset, batch_size=8, shuffle=True, drop_last=True, mask_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a38c841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6caeec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 14:42:41,888 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,890 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,891 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,892 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,893 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,893 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,894 - INFO - Masking inputs upto response query!!!\n",
      "2025-05-11 14:42:41,894 - INFO - Masking inputs upto response query!!!\n"
     ]
    }
   ],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4beeba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = first_batch[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5bc9b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###You are a very smart llm and given the input query your job is to predict the title of the input.\n",
      "### Input:\n",
      "Identify whether the following sentence is a assertion or a query. Output 1 for assertion, and 0 for query: I think this is a good idea\n",
      "### Response:\n",
      "Sentence Type Identification<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "daf16c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_response = first_batch[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b115c2b",
   "metadata": {},
   "source": [
    "### Response without masking inputs alpaca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2090dcc",
   "metadata": {},
   "source": [
    "-100 is neglected by the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8466d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Type Identification<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(sample_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c253579b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
