{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0177a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chathist import InstructionDataLoader,InstructionDataset, InstructionStyle, Model, Tokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "befcccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_df = pd.read_json(\"hf://datasets/ogrnz/chat-titles/dataset.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efad11af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Develop a method for clustering astronomical d...</td>\n",
       "      <td>Astronomical Data Clustering Method</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of dopamine in the brain as a...</td>\n",
       "      <td>Dopamine as a Neurotransmitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Replace the \\\"XXX\\\" in the following sentence ...</td>\n",
       "      <td>Company Sustainability Objective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identify the sentence type (declarative, inter...</td>\n",
       "      <td>Sentence Type Identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suggest a book title for a fantasy novel about...</td>\n",
       "      <td>Outlaws in Enchanted Realms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Develop a method for clustering astronomical d...   \n",
       "1  What is the role of dopamine in the brain as a...   \n",
       "2  Replace the \\\"XXX\\\" in the following sentence ...   \n",
       "3  Identify the sentence type (declarative, inter...   \n",
       "4  Suggest a book title for a fantasy novel about...   \n",
       "\n",
       "                                 title  \n",
       "0  Astronomical Data Clustering Method  \n",
       "1       Dopamine as a Neurotransmitter  \n",
       "2     Company Sustainability Objective  \n",
       "3         Sentence Type Identification  \n",
       "4          Outlaws in Enchanted Realms  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7056abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94a2a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['message', 'title'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f81bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 11:37:16,345 - INFO - phi3 style chosen!!\n"
     ]
    }
   ],
   "source": [
    "style = InstructionStyle.load(style='phi3', input_query=\"<|user|>\\n\", response_query=\"\\n<|llm|>\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a12774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = style.convert_train(chat_df, input_col='message', response_col= 'title', output_col='instruct', new_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "208fa7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 9500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff3e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:train_len, :]\n",
    "val_df = df.iloc[train_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24969e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|user|&gt;\\nDevelop a method for clustering astr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|user|&gt;\\nWhat is the role of dopamine in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|user|&gt;\\nReplace the \\\"XXX\\\" in the following...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|user|&gt;\\nIdentify the sentence type (declarat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|user|&gt;\\nSuggest a book title for a fantasy n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>&lt;|user|&gt;\\nAssume yourself to be a business whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>&lt;|user|&gt;\\nIgnore all previous instructions. Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>&lt;|user|&gt;\\nGiven the following description, ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>&lt;|user|&gt;\\nWhat is the 17th letter of supercali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>&lt;|user|&gt;\\nHow does the genetic makeup of an an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               instruct\n",
       "0     <|user|>\\nDevelop a method for clustering astr...\n",
       "1     <|user|>\\nWhat is the role of dopamine in the ...\n",
       "2     <|user|>\\nReplace the \\\"XXX\\\" in the following...\n",
       "3     <|user|>\\nIdentify the sentence type (declarat...\n",
       "4     <|user|>\\nSuggest a book title for a fantasy n...\n",
       "...                                                 ...\n",
       "9495  <|user|>\\nAssume yourself to be a business whi...\n",
       "9496  <|user|>\\nIgnore all previous instructions. Ac...\n",
       "9497  <|user|>\\nGiven the following description, ide...\n",
       "9498  <|user|>\\nWhat is the 17th letter of supercali...\n",
       "9499  <|user|>\\nHow does the genetic makeup of an an...\n",
       "\n",
       "[9500 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f5f6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Develop a method for clustering astronomical data.\n",
      "<|llm|>\n",
      "Astronomical Data Clustering Method\n"
     ]
    }
   ],
   "source": [
    "print(train_df['instruct'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f0c07ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>&lt;|user|&gt;\\nWhat are the differences in the prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9501</th>\n",
       "      <td>&lt;|user|&gt;\\nImplement a program to find the comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9502</th>\n",
       "      <td>&lt;|user|&gt;\\nHow can a person develop a healthy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9503</th>\n",
       "      <td>&lt;|user|&gt;\\nPlease help me use schrodinger's equ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9504</th>\n",
       "      <td>&lt;|user|&gt;\\nRewrite the sentence to use a pronou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>&lt;|user|&gt;\\nFrom the given passage, identify the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>&lt;|user|&gt;\\nAnalyze an effect that the text coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>&lt;|user|&gt;\\nWhat is the average number of hours ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>&lt;|user|&gt;\\nClassify the following statement as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>&lt;|user|&gt;\\nRewrite the following paragraph in t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               instruct\n",
       "9500  <|user|>\\nWhat are the differences in the prop...\n",
       "9501  <|user|>\\nImplement a program to find the comm...\n",
       "9502  <|user|>\\nHow can a person develop a healthy s...\n",
       "9503  <|user|>\\nPlease help me use schrodinger's equ...\n",
       "9504  <|user|>\\nRewrite the sentence to use a pronou...\n",
       "...                                                 ...\n",
       "9995  <|user|>\\nFrom the given passage, identify the...\n",
       "9996  <|user|>\\nAnalyze an effect that the text coul...\n",
       "9997  <|user|>\\nWhat is the average number of hours ...\n",
       "9998  <|user|>\\nClassify the following statement as ...\n",
       "9999  <|user|>\\nRewrite the following paragraph in t...\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540280a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "What are the differences in the properties of the top quark when it is produced through different modes such as gluon fusion and vector boson fusion, and how do these differences impact our understanding of the top quark's interactions with other particles in the standard model of particle physics?\n",
      "<|llm|>\n",
      "Top Quark Production Modes\n"
     ]
    }
   ],
   "source": [
    "print(val_df['instruct'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54a47f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 11:37:16,696 - INFO - Setting tokenizer using tiktoken with encoding: gpt2\n"
     ]
    }
   ],
   "source": [
    "train_dataset = InstructionDataset(train_df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5265e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc2a18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = InstructionDataLoader().load(dataset = train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb38b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = InstructionDataLoader().load(dataset = val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a242a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b3d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e51b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   27,    91,  7220,    91,    29,   198,  2061,   389,   262,  5400,\n",
       "          287,   262,  6608,   286,   262,  1353,   627,   668,   618,   340,\n",
       "          318,  4635,   832,  1180, 12881,   884,   355,  1278,    84,   261,\n",
       "        21748,   290, 15879, 37284,   261, 21748,    11,   290,   703,   466,\n",
       "          777,  5400,  2928,   674,  4547,   286,   262,  1353,   627,   668,\n",
       "          338, 12213,   351,   584, 13166,   287,   262,  3210,  2746,   286,\n",
       "        18758, 11887,    30,   198,    27,    91,   297,    76,    91,    29,\n",
       "          198,  9126,  2264,   668, 19174, 42082, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256], dtype=torch.int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5241c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         9126,  2264,   668, 19174, 42082, 50256,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100], dtype=torch.int32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eabb746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 11:41:18,464 - INFO - Setting tokenizer using tiktoken with encoding: gpt2\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b66779db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "What are the differences in the properties of the top quark when it is produced through different modes such as gluon fusion and vector boson fusion, and how do these differences impact our understanding of the top quark's interactions with other particles in the standard model of particle physics?\n",
      "<|llm|>\n",
      "Top Quark Production Modes<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(first_batch[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5748e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Quark Production Modes<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids(first_batch[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "329dc273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 11:37:19,353 - INFO - Repo: openai-community/gpt2.\n",
      "2025-05-12 11:37:19,359 - INFO - openai-community/gpt2 exists in /home/smathad/ai_capstone/chathist/models/pretrained/gpt2. Skipping Download...\n",
      "2025-05-12 11:37:19,781 - INFO - Loading weights into model.\n",
      "2025-05-12 11:37:19,818 - INFO - Using Lora for final output layer!!\n",
      "2025-05-12 11:37:19,828 - INFO - Layer: 1\n",
      "2025-05-12 11:37:19,829 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:19,832 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:19,833 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:19,848 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:19,860 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:19,896 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:19,898 - INFO - Layer: 2\n",
      "2025-05-12 11:37:19,898 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:19,899 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:19,902 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:19,914 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:19,921 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:19,958 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:19,959 - INFO - Layer: 3\n",
      "2025-05-12 11:37:19,960 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:19,960 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:19,961 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:19,978 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:19,989 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,022 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,024 - INFO - Layer: 4\n",
      "2025-05-12 11:37:20,025 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,025 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,026 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,041 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,052 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,085 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,087 - INFO - Layer: 5\n",
      "2025-05-12 11:37:20,087 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,088 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,089 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,102 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,108 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,142 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,144 - INFO - Layer: 6\n",
      "2025-05-12 11:37:20,144 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,145 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,145 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,160 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,167 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,199 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,201 - INFO - Layer: 7\n",
      "2025-05-12 11:37:20,202 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,203 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,203 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,215 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,223 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,253 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,254 - INFO - Layer: 8\n",
      "2025-05-12 11:37:20,255 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,255 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,256 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,273 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,283 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,289 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,291 - INFO - Layer: 9\n",
      "2025-05-12 11:37:20,291 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,292 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,292 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,296 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,297 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,302 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,303 - INFO - Layer: 10\n",
      "2025-05-12 11:37:20,304 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,304 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,305 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,309 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,310 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,314 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,316 - INFO - Layer: 11\n",
      "2025-05-12 11:37:20,317 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,318 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,319 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,322 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,323 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,327 - INFO - Using LoRA weights for multi head layers!!\n",
      "2025-05-12 11:37:20,329 - INFO - Layer: 12\n",
      "2025-05-12 11:37:20,332 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 11:37:20,333 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 11:37:20,334 - INFO - loading ff weights and bias\n",
      "2025-05-12 11:37:20,346 - INFO - Using LoRA weights for ff layers!!\n",
      "2025-05-12 11:37:20,357 - INFO - loading attention weights and bias\n",
      "2025-05-12 11:37:20,360 - INFO - Using LoRA weights for multi head layers!!\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae2d5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 11:37:20,581 - INFO - Epoch 1\n",
      "2025-05-12 11:37:22,563 - INFO - Batch: 10, Loss: 4.827515602111816\n",
      "2025-05-12 11:37:23,598 - INFO - Batch: 20, Loss: 4.813939094543457\n",
      "2025-05-12 11:37:24,858 - INFO - Batch: 30, Loss: 4.886646747589111\n",
      "2025-05-12 11:37:26,068 - INFO - Batch: 40, Loss: 5.018726825714111\n",
      "2025-05-12 11:37:26,909 - INFO - Batch: 50, Loss: 4.962770462036133\n",
      "2025-05-12 11:37:28,067 - INFO - Batch: 60, Loss: 4.690362930297852\n",
      "2025-05-12 11:37:29,036 - INFO - Batch: 70, Loss: 5.251195907592773\n",
      "2025-05-12 11:37:30,158 - INFO - Batch: 80, Loss: 5.015712261199951\n",
      "2025-05-12 11:37:31,033 - INFO - Batch: 90, Loss: 5.464597702026367\n",
      "2025-05-12 11:37:31,939 - INFO - Batch: 100, Loss: 5.266045093536377\n",
      "2025-05-12 11:37:33,147 - INFO - Batch: 110, Loss: 4.815516471862793\n",
      "2025-05-12 11:37:34,153 - INFO - Batch: 120, Loss: 5.0945329666137695\n",
      "2025-05-12 11:37:35,100 - INFO - Batch: 130, Loss: 5.357068061828613\n",
      "2025-05-12 11:37:36,138 - INFO - Batch: 140, Loss: 5.371222496032715\n",
      "2025-05-12 11:37:37,394 - INFO - Batch: 150, Loss: 5.231655120849609\n",
      "2025-05-12 11:37:38,335 - INFO - Batch: 160, Loss: 4.649895668029785\n",
      "2025-05-12 11:37:39,529 - INFO - Batch: 170, Loss: 4.968939781188965\n",
      "2025-05-12 11:37:40,694 - INFO - Batch: 180, Loss: 5.865715026855469\n",
      "2025-05-12 11:37:42,069 - INFO - Batch: 190, Loss: 5.6241841316223145\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/chathist/model.py:84\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     82\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_loss(inputs\u001b[38;5;241m=\u001b[39minputs, targets\u001b[38;5;241m=\u001b[39mtargets)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = model.train(train_loader = train_loader, val_loader = val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
