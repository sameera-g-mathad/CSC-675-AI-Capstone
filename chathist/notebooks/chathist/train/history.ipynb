{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d09df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chathist import InstructionDataLoader,InstructionDataset, InstructionStyle, Model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a17c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.read_csv(\"hf://datasets/BashitAli/Indian_history/datasetfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3681d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of studying history?</td>\n",
       "      <td>History helps us understand how early humans a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does a historian evaluate events?</td>\n",
       "      <td>Historians assess various situations over a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the historian's role in using myths?</td>\n",
       "      <td>Historians aim to verify facts from myths root...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How were ancient Indian historical events reco...</td>\n",
       "      <td>Ancient Indian history was recorded through a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who identified the oldest civilization in the ...</td>\n",
       "      <td>Archaeologist John Marshall identified the old...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0           What is the purpose of studying history?   \n",
       "1              How does a historian evaluate events?   \n",
       "2       What is the historian's role in using myths?   \n",
       "3  How were ancient Indian historical events reco...   \n",
       "4  Who identified the oldest civilization in the ...   \n",
       "\n",
       "                                            response  \n",
       "0  History helps us understand how early humans a...  \n",
       "1  Historians assess various situations over a lo...  \n",
       "2  Historians aim to verify facts from myths root...  \n",
       "3  Ancient Indian history was recorded through a ...  \n",
       "4  Archaeologist John Marshall identified the old...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e82643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14908, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090ba88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instruction', 'response'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c2924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eeec914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 13:04:37,891 - INFO - alpaca style chosen!!\n"
     ]
    }
   ],
   "source": [
    "style = InstructionStyle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09489b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = style.convert_train(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8a1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 14_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecac74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:train_len, :]\n",
    "val_df = df.iloc[train_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e31ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                instruct\n",
       "0      ### You are an assistant with deep expertise i...\n",
       "1      ### You are an assistant with deep expertise i...\n",
       "2      ### You are an assistant with deep expertise i...\n",
       "3      ### You are an assistant with deep expertise i...\n",
       "4      ### You are an assistant with deep expertise i...\n",
       "...                                                  ...\n",
       "13995  ### You are an assistant with deep expertise i...\n",
       "13996  ### You are an assistant with deep expertise i...\n",
       "13997  ### You are an assistant with deep expertise i...\n",
       "13998  ### You are an assistant with deep expertise i...\n",
       "13999  ### You are an assistant with deep expertise i...\n",
       "\n",
       "[14000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4e1888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\\n## Input:\n",
      "What is the purpose of studying history?\n",
      "## Response:\n",
      "History helps us understand how early humans adapted to their environment and developed civilizations. It involves analyzing society, economy, and culture over time to understand their impact.\n"
     ]
    }
   ],
   "source": [
    "print(train_df['instruct'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27753c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14001</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14002</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14003</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14004</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14904</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14906</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14907</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>908 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                instruct\n",
       "14000  ### You are an assistant with deep expertise i...\n",
       "14001  ### You are an assistant with deep expertise i...\n",
       "14002  ### You are an assistant with deep expertise i...\n",
       "14003  ### You are an assistant with deep expertise i...\n",
       "14004  ### You are an assistant with deep expertise i...\n",
       "...                                                  ...\n",
       "14903  ### You are an assistant with deep expertise i...\n",
       "14904  ### You are an assistant with deep expertise i...\n",
       "14905  ### You are an assistant with deep expertise i...\n",
       "14906  ### You are an assistant with deep expertise i...\n",
       "14907  ### You are an assistant with deep expertise i...\n",
       "\n",
       "[908 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc2214a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\\n## Input:\n",
      " What movement played a role in the growth and development of regional languages?\n",
      "## Response:\n",
      "The Bhakti movement.\n"
     ]
    }
   ],
   "source": [
    "print(val_df['instruct'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68458b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 13:04:38,019 - INFO - Setting tokenizer using tiktoken with encoding: gpt2\n"
     ]
    }
   ],
   "source": [
    "train_dataset = InstructionDataset(train_df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5bf387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b87297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = InstructionDataLoader().load(dataset = train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b952b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = InstructionDataLoader().load(dataset = val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db267fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bb37dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d357e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21017,   921,   389,   281,  8796,   351,  2769, 13572,   287,  3942,\n",
       "         2106,    13,   921,   481,  3280,   597,  2683,  3519,   284,  3942,\n",
       "         2106,    11,  4955,  7187,   290, 41696,  1321,    13,    59,    77,\n",
       "         2235, 23412,    25,   198,  5338, 39257,   262, 16581,   461, 20259,\n",
       "         2728,  1863,   351,  7431,   272,  5282,    30,   198,  2235, 18261,\n",
       "           25,   198,    51,  5753, 24496,    13, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61028cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,    51,  5753, 24496,    13, 50256,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5218f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 13:04:39,735 - INFO - alpaca style chosen!!\n",
      "2025-05-14 13:04:48,779 - INFO - Repo: openai-community/gpt2-xl.\n",
      "2025-05-14 13:04:48,785 - INFO - Downloading openai-community/gpt2-xl from Hugginface...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef07fc8f91ca414b9d1c6aa12c75e327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5c8f428a6141489046e290090d68c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/6.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 13:07:19,969 - INFO - Dowload complete.\n",
      "2025-05-14 13:07:19,972 - INFO - Loading weights into model.\n",
      "2025-05-14 13:07:22,998 - INFO - Layer: 1\n",
      "2025-05-14 13:07:23,000 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:23,000 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:23,001 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:23,898 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:24,355 - INFO - Layer: 2\n",
      "2025-05-14 13:07:24,356 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:24,357 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:24,358 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:25,277 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:25,729 - INFO - Layer: 3\n",
      "2025-05-14 13:07:25,730 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:25,731 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:25,731 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:26,626 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:27,095 - INFO - Layer: 4\n",
      "2025-05-14 13:07:27,096 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:27,097 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:27,098 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:27,950 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:28,362 - INFO - Layer: 5\n",
      "2025-05-14 13:07:28,363 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:28,363 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:28,364 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:29,168 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:29,588 - INFO - Layer: 6\n",
      "2025-05-14 13:07:29,588 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:29,589 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:29,590 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:30,398 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:30,812 - INFO - Layer: 7\n",
      "2025-05-14 13:07:30,813 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:30,814 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:30,814 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:31,617 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:32,027 - INFO - Layer: 8\n",
      "2025-05-14 13:07:32,028 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:32,029 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:32,029 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:32,828 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:33,250 - INFO - Layer: 9\n",
      "2025-05-14 13:07:33,251 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:33,252 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:33,252 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:34,050 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:34,469 - INFO - Layer: 10\n",
      "2025-05-14 13:07:34,470 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:34,470 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:34,471 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:35,258 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:35,671 - INFO - Layer: 11\n",
      "2025-05-14 13:07:35,672 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:35,673 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:35,673 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:36,465 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:36,884 - INFO - Layer: 12\n",
      "2025-05-14 13:07:36,884 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:36,885 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:36,886 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:37,691 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:38,109 - INFO - Layer: 13\n",
      "2025-05-14 13:07:38,110 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:38,110 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:38,111 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:38,918 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:39,329 - INFO - Layer: 14\n",
      "2025-05-14 13:07:39,330 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:39,330 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:39,331 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:40,122 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:40,537 - INFO - Layer: 15\n",
      "2025-05-14 13:07:40,538 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:40,539 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:40,539 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:41,333 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:41,743 - INFO - Layer: 16\n",
      "2025-05-14 13:07:41,744 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:41,744 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:41,745 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:42,558 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:42,975 - INFO - Layer: 17\n",
      "2025-05-14 13:07:42,976 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:42,976 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:42,977 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:43,770 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:44,185 - INFO - Layer: 18\n",
      "2025-05-14 13:07:44,186 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:44,187 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:44,187 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:44,992 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:45,400 - INFO - Layer: 19\n",
      "2025-05-14 13:07:45,401 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:45,401 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:45,402 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:46,203 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:46,621 - INFO - Layer: 20\n",
      "2025-05-14 13:07:46,622 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:46,622 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:46,623 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:47,427 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:47,837 - INFO - Layer: 21\n",
      "2025-05-14 13:07:47,837 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:47,838 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:47,839 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:48,636 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:49,057 - INFO - Layer: 22\n",
      "2025-05-14 13:07:49,058 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:49,059 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:49,059 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:49,851 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:50,268 - INFO - Layer: 23\n",
      "2025-05-14 13:07:50,269 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:50,269 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:50,270 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:51,058 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:51,464 - INFO - Layer: 24\n",
      "2025-05-14 13:07:51,465 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:51,466 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:51,466 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:52,266 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:52,679 - INFO - Layer: 25\n",
      "2025-05-14 13:07:52,680 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:52,680 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:52,681 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:53,475 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:53,896 - INFO - Layer: 26\n",
      "2025-05-14 13:07:53,897 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:53,898 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:53,898 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:54,690 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:55,110 - INFO - Layer: 27\n",
      "2025-05-14 13:07:55,110 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:55,111 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:55,112 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:55,904 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:56,325 - INFO - Layer: 28\n",
      "2025-05-14 13:07:56,326 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:56,326 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:56,327 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:57,123 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:57,547 - INFO - Layer: 29\n",
      "2025-05-14 13:07:57,548 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:57,548 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:57,549 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:58,346 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:58,776 - INFO - Layer: 30\n",
      "2025-05-14 13:07:58,776 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:58,777 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:58,778 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:07:59,569 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:07:59,981 - INFO - Layer: 31\n",
      "2025-05-14 13:07:59,982 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:07:59,983 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:07:59,984 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:00,780 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:01,199 - INFO - Layer: 32\n",
      "2025-05-14 13:08:01,200 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:01,200 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:01,201 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:02,004 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:02,421 - INFO - Layer: 33\n",
      "2025-05-14 13:08:02,422 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:02,423 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:02,423 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:03,221 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:03,647 - INFO - Layer: 34\n",
      "2025-05-14 13:08:03,648 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:03,649 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:03,650 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:04,456 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:04,877 - INFO - Layer: 35\n",
      "2025-05-14 13:08:04,878 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:04,879 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:04,879 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:05,688 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:06,114 - INFO - Layer: 36\n",
      "2025-05-14 13:08:06,115 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:06,116 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:06,117 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:06,910 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:07,331 - INFO - Layer: 37\n",
      "2025-05-14 13:08:07,331 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:07,332 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:07,333 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:08,136 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:08,552 - INFO - Layer: 38\n",
      "2025-05-14 13:08:08,553 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:08,553 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:08,554 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:09,350 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:09,768 - INFO - Layer: 39\n",
      "2025-05-14 13:08:09,769 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:09,769 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:09,770 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:10,564 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:10,987 - INFO - Layer: 40\n",
      "2025-05-14 13:08:10,988 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:10,988 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:10,989 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:11,782 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:12,198 - INFO - Layer: 41\n",
      "2025-05-14 13:08:12,199 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:12,200 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:12,200 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:13,002 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:13,419 - INFO - Layer: 42\n",
      "2025-05-14 13:08:13,420 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:13,421 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:13,421 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:14,223 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:14,635 - INFO - Layer: 43\n",
      "2025-05-14 13:08:14,636 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:14,637 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:14,638 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:15,427 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:15,836 - INFO - Layer: 44\n",
      "2025-05-14 13:08:15,837 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:15,837 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:15,838 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:16,644 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:17,044 - INFO - Layer: 45\n",
      "2025-05-14 13:08:17,045 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:17,046 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:17,046 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:17,827 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:18,236 - INFO - Layer: 46\n",
      "2025-05-14 13:08:18,238 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:18,239 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:18,239 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:19,015 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:19,417 - INFO - Layer: 47\n",
      "2025-05-14 13:08:19,418 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:19,419 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:19,419 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:20,198 - INFO - loading attention weights and bias\n",
      "2025-05-14 13:08:20,599 - INFO - Layer: 48\n",
      "2025-05-14 13:08:20,599 - INFO - loading norm1 weights and bias\n",
      "2025-05-14 13:08:20,600 - INFO - loading norm2 weights and bias\n",
      "2025-05-14 13:08:20,601 - INFO - loading ff weights and bias\n",
      "2025-05-14 13:08:21,372 - INFO - loading attention weights and bias\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 21.62 MiB is free. Process 2359628 has 72.17 GiB memory in use. Process 2361045 has 3.61 GiB memory in use. Including non-PyTorch memory, this process has 3.43 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 15.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/chathist/model.py:58\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_learning_rate, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 915 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 21.62 MiB is free. Process 2359628 has 72.17 GiB memory in use. Process 2361045 has 3.61 GiB memory in use. Including non-PyTorch memory, this process has 3.43 GiB memory in use. Of the allocated memory 2.93 GiB is allocated by PyTorch, and 15.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f84052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model.get_model_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7b7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss = model.train(train_loader = train_loader, val_loader = val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0004e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['instruct'].values[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate('''### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\n",
    "## Input:\n",
    "How do geological studies contribute to understanding history?\n",
    "## Response:\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a705d933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
