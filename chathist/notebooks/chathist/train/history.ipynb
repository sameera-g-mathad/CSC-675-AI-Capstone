{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d09df26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:09:04,247 - WARNING - data is not present in the config file, falling back to defaults!!!\n"
     ]
    }
   ],
   "source": [
    "from chathist import InstructionDataLoader,InstructionDataset, InstructionStyle, Model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a17c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.read_csv(\"hf://datasets/BashitAli/Indian_history/datasetfile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3681d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of studying history?</td>\n",
       "      <td>History helps us understand how early humans a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How does a historian evaluate events?</td>\n",
       "      <td>Historians assess various situations over a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the historian's role in using myths?</td>\n",
       "      <td>Historians aim to verify facts from myths root...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How were ancient Indian historical events reco...</td>\n",
       "      <td>Ancient Indian history was recorded through a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Who identified the oldest civilization in the ...</td>\n",
       "      <td>Archaeologist John Marshall identified the old...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0           What is the purpose of studying history?   \n",
       "1              How does a historian evaluate events?   \n",
       "2       What is the historian's role in using myths?   \n",
       "3  How were ancient Indian historical events reco...   \n",
       "4  Who identified the oldest civilization in the ...   \n",
       "\n",
       "                                            response  \n",
       "0  History helps us understand how early humans a...  \n",
       "1  Historians assess various situations over a lo...  \n",
       "2  Historians aim to verify facts from myths root...  \n",
       "3  Ancient Indian history was recorded through a ...  \n",
       "4  Archaeologist John Marshall identified the old...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e82643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14908, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090ba88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['instruction', 'response'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c2924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eeec914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:09:04,695 - INFO - alpaca style chosen!!\n"
     ]
    }
   ],
   "source": [
    "style = InstructionStyle.load(style='alpaca', prompt=prompt, input_query=\"## Input:\\n\", response_query=\"\\n## Response:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09489b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = style.convert_train(history_df, input_col='instruction', response_col= 'response', output_col='instruct', new_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c8a1f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecac74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:train_len, :]\n",
    "val_df = df.iloc[train_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e31ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              instruct\n",
       "0    ### You are an assistant with deep expertise i...\n",
       "1    ### You are an assistant with deep expertise i...\n",
       "2    ### You are an assistant with deep expertise i...\n",
       "3    ### You are an assistant with deep expertise i...\n",
       "4    ### You are an assistant with deep expertise i...\n",
       "..                                                 ...\n",
       "995  ### You are an assistant with deep expertise i...\n",
       "996  ### You are an assistant with deep expertise i...\n",
       "997  ### You are an assistant with deep expertise i...\n",
       "998  ### You are an assistant with deep expertise i...\n",
       "999  ### You are an assistant with deep expertise i...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb4e1888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\n",
      "## Input:\n",
      "What is the purpose of studying history?\n",
      "## Response:\n",
      "History helps us understand how early humans adapted to their environment and developed civilizations. It involves analyzing society, economy, and culture over time to understand their impact.\n"
     ]
    }
   ],
   "source": [
    "print(train_df['instruct'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27753c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14903</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14904</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14905</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14906</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14907</th>\n",
       "      <td>### You are an assistant with deep expertise i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13908 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                instruct\n",
       "1000   ### You are an assistant with deep expertise i...\n",
       "1001   ### You are an assistant with deep expertise i...\n",
       "1002   ### You are an assistant with deep expertise i...\n",
       "1003   ### You are an assistant with deep expertise i...\n",
       "1004   ### You are an assistant with deep expertise i...\n",
       "...                                                  ...\n",
       "14903  ### You are an assistant with deep expertise i...\n",
       "14904  ### You are an assistant with deep expertise i...\n",
       "14905  ### You are an assistant with deep expertise i...\n",
       "14906  ### You are an assistant with deep expertise i...\n",
       "14907  ### You are an assistant with deep expertise i...\n",
       "\n",
       "[13908 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc2214a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\n",
      "## Input:\n",
      " What social changes occurred in the later Vedic phase regarding women and restrictions on them?\n",
      "## Response:\n",
      "In the later Vedic phase, some restrictions on women appeared, with texts counting women as a vice and limiting their participation in public meetings.\n"
     ]
    }
   ],
   "source": [
    "print(val_df['instruct'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68458b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:09:04,833 - INFO - Setting tokenizer using tiktoken with encoding: gpt2\n"
     ]
    }
   ],
   "source": [
    "train_dataset = InstructionDataset(train_df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5bf387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = InstructionDataset(val_df['instruct'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b87297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = InstructionDataLoader().load(dataset = train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46b952b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = InstructionDataLoader().load(dataset = val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db267fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bb37dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_batch = next(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d357e590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21017,   921,   389,   281,  8796,   351,  2769, 13572,   287,  3942,\n",
       "         2106,    13,   921,   481,  3280,   597,  2683,  3519,   284,  3942,\n",
       "         2106,    11,  4955,  7187,   290, 41696,  1321,    13,   198,  2235,\n",
       "        23412,    25,   198,  1867,  1919,  2458,  5091,   287,   262,  1568,\n",
       "        36101,   291,  7108,  5115,  1466,   290,  8733,   319,   606,    30,\n",
       "          198,  2235, 18261,    25,   198,   818,   262,  1568, 36101,   291,\n",
       "         7108,    11,   617,  8733,   319,  1466,  4120,    11,   351, 13399,\n",
       "        14143,  1466,   355,   257,  7927,   290, 15637,   511, 10270,   287,\n",
       "         1171,  8292,    13, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256], dtype=torch.int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61028cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,   818,   262,  1568, 36101,   291,  7108,\n",
       "           11,   617,  8733,   319,  1466,  4120,    11,   351, 13399, 14143,\n",
       "         1466,   355,   257,  7927,   290, 15637,   511, 10270,   287,  1171,\n",
       "         8292,    13, 50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5218f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:09:07,675 - INFO - Repo: openai-community/gpt2.\n",
      "2025-05-12 13:09:07,676 - INFO - openai-community/gpt2 exists in /home/smathad/ai_capstone/chathist/models/pretrained/gpt2. Skipping Download...\n",
      "2025-05-12 13:09:08,094 - INFO - Loading weights into model.\n",
      "2025-05-12 13:09:08,137 - INFO - Layer: 1\n",
      "2025-05-12 13:09:08,138 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,138 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,139 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,155 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,182 - INFO - Layer: 2\n",
      "2025-05-12 13:09:08,183 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,183 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,184 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,194 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,197 - INFO - Layer: 3\n",
      "2025-05-12 13:09:08,197 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,198 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,198 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,200 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,203 - INFO - Layer: 4\n",
      "2025-05-12 13:09:08,203 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,204 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,204 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,206 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,208 - INFO - Layer: 5\n",
      "2025-05-12 13:09:08,209 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,209 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,210 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,211 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,215 - INFO - Layer: 6\n",
      "2025-05-12 13:09:08,215 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,216 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,216 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,219 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,222 - INFO - Layer: 7\n",
      "2025-05-12 13:09:08,222 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,223 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,223 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,226 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,229 - INFO - Layer: 8\n",
      "2025-05-12 13:09:08,230 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,230 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,231 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,233 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,237 - INFO - Layer: 9\n",
      "2025-05-12 13:09:08,237 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,238 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,238 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,241 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,245 - INFO - Layer: 10\n",
      "2025-05-12 13:09:08,245 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,246 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,251 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,255 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,259 - INFO - Layer: 11\n",
      "2025-05-12 13:09:08,260 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,261 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,262 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,265 - INFO - loading attention weights and bias\n",
      "2025-05-12 13:09:08,270 - INFO - Layer: 12\n",
      "2025-05-12 13:09:08,272 - INFO - loading norm1 weights and bias\n",
      "2025-05-12 13:09:08,273 - INFO - loading norm2 weights and bias\n",
      "2025-05-12 13:09:08,274 - INFO - loading ff weights and bias\n",
      "2025-05-12 13:09:08,277 - INFO - loading attention weights and bias\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99f84052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163037184"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._model.get_model_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a329dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tok_emb.weight\n",
      "True\n",
      "pos_emb.weight\n",
      "True\n",
      "transformers.layer_0.norm1.scale\n",
      "True\n",
      "transformers.layer_0.norm1.shift\n",
      "True\n",
      "transformers.layer_0.norm2.scale\n",
      "True\n",
      "transformers.layer_0.norm2.shift\n",
      "True\n",
      "transformers.layer_0.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_0.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_0.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_0.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_0.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_0.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_0.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_0.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_0.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_0.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_0.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_0.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_1.norm1.scale\n",
      "True\n",
      "transformers.layer_1.norm1.shift\n",
      "True\n",
      "transformers.layer_1.norm2.scale\n",
      "True\n",
      "transformers.layer_1.norm2.shift\n",
      "True\n",
      "transformers.layer_1.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_1.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_1.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_1.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_1.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_1.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_1.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_1.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_1.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_1.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_1.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_1.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_2.norm1.scale\n",
      "True\n",
      "transformers.layer_2.norm1.shift\n",
      "True\n",
      "transformers.layer_2.norm2.scale\n",
      "True\n",
      "transformers.layer_2.norm2.shift\n",
      "True\n",
      "transformers.layer_2.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_2.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_2.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_2.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_2.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_2.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_2.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_2.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_2.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_2.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_2.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_2.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_3.norm1.scale\n",
      "True\n",
      "transformers.layer_3.norm1.shift\n",
      "True\n",
      "transformers.layer_3.norm2.scale\n",
      "True\n",
      "transformers.layer_3.norm2.shift\n",
      "True\n",
      "transformers.layer_3.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_3.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_3.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_3.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_3.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_3.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_3.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_3.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_3.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_3.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_3.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_3.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_4.norm1.scale\n",
      "True\n",
      "transformers.layer_4.norm1.shift\n",
      "True\n",
      "transformers.layer_4.norm2.scale\n",
      "True\n",
      "transformers.layer_4.norm2.shift\n",
      "True\n",
      "transformers.layer_4.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_4.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_4.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_4.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_4.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_4.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_4.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_4.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_4.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_4.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_4.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_4.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_5.norm1.scale\n",
      "True\n",
      "transformers.layer_5.norm1.shift\n",
      "True\n",
      "transformers.layer_5.norm2.scale\n",
      "True\n",
      "transformers.layer_5.norm2.shift\n",
      "True\n",
      "transformers.layer_5.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_5.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_5.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_5.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_5.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_5.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_5.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_5.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_5.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_5.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_5.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_5.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_6.norm1.scale\n",
      "True\n",
      "transformers.layer_6.norm1.shift\n",
      "True\n",
      "transformers.layer_6.norm2.scale\n",
      "True\n",
      "transformers.layer_6.norm2.shift\n",
      "True\n",
      "transformers.layer_6.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_6.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_6.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_6.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_6.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_6.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_6.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_6.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_6.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_6.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_6.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_6.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_7.norm1.scale\n",
      "True\n",
      "transformers.layer_7.norm1.shift\n",
      "True\n",
      "transformers.layer_7.norm2.scale\n",
      "True\n",
      "transformers.layer_7.norm2.shift\n",
      "True\n",
      "transformers.layer_7.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_7.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_7.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_7.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_7.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_7.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_7.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_7.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_7.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_7.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_7.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_7.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_8.norm1.scale\n",
      "True\n",
      "transformers.layer_8.norm1.shift\n",
      "True\n",
      "transformers.layer_8.norm2.scale\n",
      "True\n",
      "transformers.layer_8.norm2.shift\n",
      "True\n",
      "transformers.layer_8.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_8.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_8.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_8.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_8.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_8.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_8.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_8.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_8.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_8.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_8.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_8.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_9.norm1.scale\n",
      "True\n",
      "transformers.layer_9.norm1.shift\n",
      "True\n",
      "transformers.layer_9.norm2.scale\n",
      "True\n",
      "transformers.layer_9.norm2.shift\n",
      "True\n",
      "transformers.layer_9.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_9.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_9.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_9.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_9.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_9.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_9.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_9.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_9.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_9.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_9.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_9.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_10.norm1.scale\n",
      "True\n",
      "transformers.layer_10.norm1.shift\n",
      "True\n",
      "transformers.layer_10.norm2.scale\n",
      "True\n",
      "transformers.layer_10.norm2.shift\n",
      "True\n",
      "transformers.layer_10.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_10.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_10.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_10.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_10.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_10.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_10.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_10.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_10.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_10.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_10.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_10.multi_head.out_form.bias\n",
      "True\n",
      "transformers.layer_11.norm1.scale\n",
      "True\n",
      "transformers.layer_11.norm1.shift\n",
      "True\n",
      "transformers.layer_11.norm2.scale\n",
      "True\n",
      "transformers.layer_11.norm2.shift\n",
      "True\n",
      "transformers.layer_11.mlp.layer1.weight\n",
      "True\n",
      "transformers.layer_11.mlp.layer1.bias\n",
      "True\n",
      "transformers.layer_11.mlp.layer2.weight\n",
      "True\n",
      "transformers.layer_11.mlp.layer2.bias\n",
      "True\n",
      "transformers.layer_11.multi_head.wq.weight\n",
      "True\n",
      "transformers.layer_11.multi_head.wq.bias\n",
      "True\n",
      "transformers.layer_11.multi_head.wk.weight\n",
      "True\n",
      "transformers.layer_11.multi_head.wk.bias\n",
      "True\n",
      "transformers.layer_11.multi_head.wv.weight\n",
      "True\n",
      "transformers.layer_11.multi_head.wv.bias\n",
      "True\n",
      "transformers.layer_11.multi_head.out_form.weight\n",
      "True\n",
      "transformers.layer_11.multi_head.out_form.bias\n",
      "True\n",
      "final_norm.scale\n",
      "True\n",
      "final_norm.shift\n",
      "True\n",
      "final_layer.weight\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for name, layer in model._model.named_parameters():\n",
    "    print(name)\n",
    "    print(layer.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7cb7b7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 13:09:08,460 - INFO - Epoch 1\n",
      "2025-05-12 13:09:09,583 - INFO - Batch: 10, Loss: 3.400249481201172\n",
      "2025-05-12 13:09:10,529 - INFO - Batch: 20, Loss: 3.7190098762512207\n",
      "2025-05-12 13:09:11,650 - INFO - Batch: 30, Loss: 3.7939205169677734\n",
      "2025-05-12 13:09:12,789 - INFO - Batch: 40, Loss: 3.560229778289795\n",
      "2025-05-12 13:09:13,817 - INFO - Batch: 50, Loss: 2.8693087100982666\n",
      "2025-05-12 13:09:15,002 - INFO - Batch: 60, Loss: 3.173578977584839\n",
      "2025-05-12 13:09:15,184 - INFO - Epoch 2\n",
      "2025-05-12 13:09:16,113 - INFO - Batch: 10, Loss: 3.3762712478637695\n",
      "2025-05-12 13:09:17,061 - INFO - Batch: 20, Loss: 3.7956244945526123\n",
      "2025-05-12 13:09:18,181 - INFO - Batch: 30, Loss: 3.7992913722991943\n",
      "2025-05-12 13:09:19,325 - INFO - Batch: 40, Loss: 3.6283605098724365\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_loss, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/chathist/model.py:84\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     82\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_loss(inputs\u001b[38;5;241m=\u001b[39minputs, targets\u001b[38;5;241m=\u001b[39mtargets)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ai_capstone/chathist/venv/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = model.train(train_loader = train_loader, val_loader = val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0004e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['instruct'].values[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b66864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.generate('''### You are an assistant with deep expertise in Indian history. You will answer any questions related to Indian history, providing accurate and insightful information.\n",
    "## Input:\n",
    "Who challenged the idea of Indian despotism, and what did they assert about ancient Indian governance?\n",
    "## Response:\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99585c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
